{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM6c/4dxjntSuH/u7bK6Fk+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sergiokapone/DataScience/blob/main/Hw7/Hw7_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Завдання\n",
        "Візьміть датасет [movielens](https://surprise.readthedocs.io/en/stable/dataset.html) і побудуйте модель матричної факторизації. У даній бібліотеці він має назву SVD. Підберіть найкращі параметри за допомогою крос-валідації, також поекспериментуйте з іншими [алгоритмами](https://surprise.readthedocs.io/en/stable/prediction_algorithms_package.html) розрахунків (SVD++, NMF) і оберіть той, який буде оптимальним.\n"
      ],
      "metadata": {
        "id": "3rzBNxM-V8dj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-surprise"
      ],
      "metadata": {
        "id": "meODLrJk48rX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee360250-79c4-48de-e82e-d065553dabf7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-surprise\n",
            "  Downloading scikit-surprise-1.1.3.tar.gz (771 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m772.0/772.0 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.3.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.11.3)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.3-cp310-cp310-linux_x86_64.whl size=3163333 sha256=9335fb54bb2bb61dee2964ef384be9a76a686a0c74832801819c34f2c05643d2\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/ca/a8/4e28def53797fdc4363ca4af740db15a9c2f1595ebc51fb445\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise\n",
            "Successfully installed scikit-surprise-1.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise import SVD, SVDpp, NMF\n",
        "from surprise import Dataset\n",
        "from surprise import accuracy\n",
        "from surprise.model_selection import train_test_split, cross_validate\n",
        "from hyperopt import hp, fmin, tpe, Trials\n"
      ],
      "metadata": {
        "id": "TNBaguEM5OJG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the movielens-100k dataset (download it if needed).\n",
        "data = Dataset.load_builtin('ml-100k')"
      ],
      "metadata": {
        "id": "N0IhpCdb9NAw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fc4ca7f-609a-4d3d-824a-760f0403a23e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset ml-100k could not be found. Do you want to download it? [Y/n] "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sample random trainset and testset\n",
        "# test set is made of 25% of the ratings.\n",
        "train_set, test_set = train_test_split(data, test_size=0.25)"
      ],
      "metadata": {
        "id": "6MM0nzS7US27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "space_svd = {\n",
        "    'n_factors': hp.choice('n_factors', [50, 100, 150]),\n",
        "    'n_epochs': hp.choice('n_epochs', [10, 20, 30]),\n",
        "    'lr_all': hp.uniform('lr_all', 0.001, 0.1),\n",
        "    'reg_all': hp.uniform('reg_all', 0.01, 0.2),\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "space_nmf = {\n",
        "        'n_factors': hp.choice('n_factors', [5, 10, 15, 20, 25]),\n",
        "        'n_epochs': hp.choice('n_epochs', [10, 20, 30, 40, 50]),\n",
        "        'biased': hp.choice('biased', [True, False]),\n",
        "        'reg_pu': hp.uniform('reg_pu', 0.001, 0.1),\n",
        "        'reg_qi': hp.uniform('reg_qi', 0.001, 0.1),\n",
        "        'lr_bu': hp.uniform('lr_bu', 0.001, 0.1),\n",
        "        'lr_bi': hp.uniform('lr_bi', 0.001, 0.1),\n",
        "        'random_state': 42\n",
        "    }"
      ],
      "metadata": {
        "id": "KioJXQjYYBJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функція для обчислення RMSE\n",
        "def objective(params, func):\n",
        "    model = func(**params)\n",
        "    model.fit(train_set)\n",
        "    predictions = model.test(test_set)\n",
        "    rmse = accuracy.rmse(predictions)\n",
        "    return rmse\n",
        "\n",
        "best_params = []\n",
        "for i, func in enumerate([SVD, SVDpp, NMF]):\n",
        "    print('-------------------------')\n",
        "    print(f'Srart: {func.__name__}')\n",
        "    print('-------------------------')\n",
        "    space=[space_svd, space_svd, space_nmf]\n",
        "\n",
        "    best = fmin(fn=lambda params: objective(params, func), space=space[i], algo=tpe.suggest, max_evals=2)\n",
        "    best_params.append({func.__name__: best})\n",
        "\n",
        "best_params"
      ],
      "metadata": {
        "id": "v1_knE0p9Xee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Побудова моделі SVD\n",
        "model_svdpp = SVD(**best_params[0].get('SVD'))\n",
        "results_svdpp = cross_validate(model_svdpp, data, measures=['MSE', 'MAE'], cv=5, verbose=True)"
      ],
      "metadata": {
        "id": "xrG1UohoTb7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Побудова моделі NMF\n",
        "model_nmf = NMF(**best_params[2].get('NMF'))\n",
        "results_nmf = cross_validate(model_nmf, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
      ],
      "metadata": {
        "id": "ImjMgi40TuYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Побудова моделі SVDpp\n",
        "model_svdpp = SVDpp(**best_params[1].get('SVDpp'))\n",
        "results_nmf = cross_validate(model_svdpp, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
      ],
      "metadata": {
        "id": "Ev5x8pCpVNsS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}