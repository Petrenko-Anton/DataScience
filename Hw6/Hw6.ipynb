{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Теорія"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Означення"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кластерний аналіз (англ. Data clustering) — задача розбиття заданої вибірки об'єктів (ситуацій) на підмножини, які називаються кластерами, так, щоб кожен кластер складався зі схожих об'єктів, а об'єкти різних кластерів істотно відрізнялися. Задача кластеризації належить до статистичної обробки, а також до широкого класу завдань некерованого навчання."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кластериза́ція ме́тодом k-сере́дніх (англ. k-means clustering) - впорядкування множини об'єктів у порівняно однорідні групи.\n",
    "\n",
    "Мета методу - розділити $n$ спостережень на $k$ кластерів, так щоб кожне спостереження належало до кластера з найближчим до нього середнім значенням. Метод базується на мінімізації суми квадратів відстаней між кожним спостереженням та центром його кластера, тобто функції:\n",
    "\n",
    "\\begin{equation*}\n",
    "    J = \\sum_{i=1}^{n} \\sum_{j=1}^{k} (x_i - с_j)^2\n",
    "\\end{equation*}\n",
    "\n",
    "де $k$ — число кластерів, $n$ — число спостережень, $x_i$ - $i$-те спостереження, $c_j$ - центри мас $j$-го кластера.\n",
    "\n",
    "Фунцкція $J$ - це функція втрат, котру для кластеризації ще називають `distortion`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Алгоритм методу «Кластеризація за схемою k-середніх»:\n",
    "\n",
    "Маємо масив спостережень (об'єктів), кожен з яких має певні значення за рядом ознак. Відповідно до цих значень об'єкт розташовується у багатовимірному просторі.\n",
    "\n",
    "1. Дослідник визначає кількість кластерів, що необхідно утворити.\n",
    "2. Випадковим чином обирається $n$ спостережень, які на цьому кроці вважаються центрами кластерів.\n",
    "3. Кожне спостереження «приписується» до одного з $k$ кластерів — того, відстань до якого найкоротша.\n",
    "4. Розраховується новий центр кожного кластера як елемент, ознаки якого розраховуються як середнє арифметичне ознак об'єктів, що входять у цей кластер.\n",
    "5. Відбувається така кількість ітерацій (повторюються кроки 3-4), поки кластерні центри стануть стійкими (тобто при кожній ітерації в кожен кластер потрапляють одні й ті самі об'єкти), дисперсія всередині кластера буде мінімізована, а між кластерами — максимізована.\n",
    "\n",
    "Вибір кількості кластерів робиться на основі дослідницької гіпотези. Якщо її немає, то рекомендують спочатку створити 2 кластери, далі 3, 4, 5, порівнюючи отримані результати."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метод \"ліктя\"\n",
    "\n",
    "Метод ліктя передбачає багаторазове циклічне виконання алгоритму зі збільшенням кількості кластерів, а також подальшим відкладанням на графіку функції втрат (`distortion`).\n",
    "\n",
    "Характерный график выглядит так:\n",
    "\n",
    "![Alt text](image/kmean.png)\n",
    "\n",
    "Графік \"ліктя\" показує залежність функції втрат $J$ від кількості кластерів $k$. Якщо на графіку можна виокремити точку згину (так званий \"лікоть\"), то це може свідчити про те, що відповідна кількість кластерів є оптимальною."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Посилання\n",
    "\n",
    "1. [Алгоритм кластеризации Ллойда (K-средних, K-means)](https://www.youtube.com/watch?v=8vCuR1AndH0)\n",
    "2. [Модель кластеризации KMeans](https://www.youtube.com/watch?v=EHZJMz6zyFE&ab_channel=machinelearrrning)\n",
    "3. [Документация skikit-learn. 2.3. Кластеризация](https://scikit-learn.ru/clustering/#)\n",
    "4. [sklearn.cluster.KMeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)\n",
    "5. [Кластеризуем лучше, чем «метод локтя»](https://habr.com/ru/companies/jetinfosystems/articles/467745/)\n",
    "6. [Кластерный анализ](https://www.dmitrymakarov.ru/intro/clustering-16/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Функції"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функція для пошуку кластерів"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_clusters(features, max_clusters, random_state=0) -> list:\n",
    "    \"\"\"\n",
    "    Find the optimal number of clusters using the 'Elbow Method' for K-Means clustering.\n",
    "\n",
    "    Parameters:\n",
    "        data (array-like): The input data for clustering.\n",
    "        max_clusters (int): The maximum number of clusters to consider.\n",
    "\n",
    "    Returns:\n",
    "        distortions: list of distorsions\n",
    "\n",
    "    This function calculates the distortion (inertia) for different numbers of clusters\n",
    "    ranging from 1 to max_clusters and plots a 'Elbow Method' graph to help choose the\n",
    "    optimal number of clusters for K-Means clustering. The point where the distortion\n",
    "    starts to decrease at a slower rate often indicates the optimal number of clusters.\n",
    "    \"\"\"\n",
    "    \n",
    "    distortions = []\n",
    "    for i in range(1, max_clusters + 1):\n",
    "        kmeans = KMeans(\n",
    "            n_clusters=i,\n",
    "            init=\"k-means++\",\n",
    "            max_iter=100,\n",
    "            n_init=\"auto\",\n",
    "            random_state=random_state,\n",
    "        ).fit(features)\n",
    "        distortions.append(kmeans.inertia_)\n",
    "    \n",
    "    # plotting\n",
    "    plt.plot(range(1, max_clusters + 1), distortions)\n",
    "    plt.plot(range(1, max_clusters + 1), distortions)\n",
    "    plt.xticks(range(1, max_clusters + 1), rotation=45)\n",
    "    plt.xlabel(r\"Number of clusters, $k$\")\n",
    "    plt.ylabel(r\"Loss function (distortion)\")\n",
    "    plt.title(\"Elbow chart\")\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    return distortions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функція для виконання алгоритму кластеризації за методом K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_kmeans_clustering(features, n_clusters=8, random_state=0):\n",
    "    \"\"\"\n",
    "    Performs clustering using the K-Means method and returns cluster labels and centroid coordinates.\n",
    "\n",
    "    Parameters:\n",
    "    - features: The array of features to cluster.\n",
    "    - n_clusters: Number of clusters (default is 8).\n",
    "    - random_state: The seed for generating random numbers (default 0).\n",
    "\n",
    "    Returns:\n",
    "    - cluster_labels: An array of cluster labels.\n",
    "    - centroids: The coordinates of the centroids of the clusters.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a K-Means object\n",
    "    kmeans = KMeans(\n",
    "        n_clusters=n_clusters,\n",
    "        init=\"k-means++\",\n",
    "        max_iter=100,\n",
    "        n_init=\"auto\",\n",
    "        random_state=0,\n",
    "    )\n",
    "\n",
    "    # Clustering\n",
    "    kmeans.fit(features)\n",
    "\n",
    "    # Get cluster labels\n",
    "    cluster_labels = kmeans.labels_\n",
    "\n",
    "    # Пget the coordinates of centroids\n",
    "    centroids = kmeans.cluster_centers_\n",
    "\n",
    "    return cluster_labels, centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Двовимірний датасет `data_2d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.768716</td>\n",
       "      <td>0.460860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.687848</td>\n",
       "      <td>2.366961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.201379</td>\n",
       "      <td>0.470430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.608496</td>\n",
       "      <td>1.225400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.082282</td>\n",
       "      <td>1.137218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.629144</td>\n",
       "      <td>4.378584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.723824</td>\n",
       "      <td>5.361801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.346107</td>\n",
       "      <td>2.333476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.608219</td>\n",
       "      <td>3.411546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.764228</td>\n",
       "      <td>4.372587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2\n",
       "0    0.0 -0.768716  0.460860\n",
       "1    0.0  2.687848  2.366961\n",
       "2    0.0 -0.201379  0.470430\n",
       "3    0.0  0.608496  1.225400\n",
       "4    0.0 -0.082282  1.137218\n",
       "..   ...       ...       ...\n",
       "195  1.0  0.629144  4.378584\n",
       "196  1.0 -0.723824  5.361801\n",
       "197  1.0  1.346107  2.333476\n",
       "198  1.0  3.608219  3.411546\n",
       "199  1.0  3.764228  4.372587\n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2d = pd.read_csv(\"data/data_2d.csv\", header=None)\n",
    "data_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Цей набір даних складається з 200 рядків і 3 стовпців. Перший стовпчик - це клас, який може набувати лише двох значень: $0$ або $1$. Другий стовпець - це перша ознака, яка є дійсним числом. Третій стовпець - це друга ознака, яка також є дійсним числом. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Побудуємо розподіл даних."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "# Ознака 1 - Графік \"ящик із вусами\"\n",
    "ax1.boxplot(\n",
    "    data_2d[1],\n",
    "    vert=False,\n",
    "    widths=0.7,\n",
    "    patch_artist=True,\n",
    "    boxprops=dict(facecolor=\"lightblue\"),\n",
    "    medianprops={\"color\": \"red\"},\n",
    ")\n",
    "ax1.set_title(\"Ознака 1\")\n",
    "ax1.set_yticks([])\n",
    "ax1.spines[\"left\"].set_visible(False)\n",
    "ax1.spines[\"top\"].set_visible(False)\n",
    "ax1.spines[\"right\"].set_visible(False)\n",
    "\n",
    "# Ознака 2 - Графік \"ящик із вусами\"\n",
    "ax2.boxplot(\n",
    "    data_2d[2],\n",
    "    vert=False,\n",
    "    widths=0.7,\n",
    "    patch_artist=True,\n",
    "    boxprops=dict(facecolor=\"lightcoral\"),\n",
    "    medianprops={\"color\": \"blue\"},\n",
    ")\n",
    "ax2.set_title(\"Ознака 2\")\n",
    "ax2.set_yticks([])\n",
    "ax2.spines[\"left\"].set_visible(False)\n",
    "ax2.spines[\"top\"].set_visible(False)\n",
    "ax2.spines[\"right\"].set_visible(False)\n",
    "\n",
    "# Діаграма розсіювання\n",
    "scatter = ax3.scatter(\n",
    "    data_2d[1], data_2d[2], c=data_2d[0], s=30, cmap=\"RdYlBu\", alpha=0.75\n",
    ")\n",
    "ax3.set_title(\"Scatter plot\")\n",
    "ax3.set_xlabel(\"Feature 1\")\n",
    "ax3.set_ylabel(\"Feature 2\")\n",
    "ax3.legend(*scatter.legend_elements(), title=\"Класи\", loc=\"upper right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Додамо кольорові фони для кожного графіка\n",
    "ax1.set_facecolor(\"#f5f5f5\")\n",
    "ax2.set_facecolor(\"#f5f5f5\")\n",
    "ax3.set_facecolor(\"#f5f5f5\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Розрахунок кореляції\n",
    "corr = np.corrcoef(data_2d[1], data_2d[2])\n",
    "print(corr[0, 1].round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На основі графіків та коефіцієнта кореляції можна зробити висновки про дані:\n",
    "- Розподіл першої ознаки: нормальний.\n",
    "- Розподіл другої ознаки: нормальний.\n",
    "- Кореляція між ознаками: слабка."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Знаходження оптимальної кількості кластерів"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data_2d.iloc[:, 1:]\n",
    "\n",
    "Jk_data_2d = find_optimal_clusters(features, max_clusters=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Судячи з графіку число кластерів для `data_2d` дорівнює $2$. Крім того в наших даних перша колонка скоріше за все є класом ознаки. Таких ознак в даних також $2$-і."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Запуск алгоритму класифікації"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_data_2d = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels, centroids = perform_kmeans_clustering(features, n_clusters=k_data_2d)\n",
    "\n",
    "X_ceterod = centroids[:, 0]\n",
    "y_centroid = centroids[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Візуалізація результат роботи кластеризації"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кластери\n",
    "plt.scatter(x=data_2d[1], y=data_2d[2], s=10, c=cluster_labels, cmap='rainbow')\n",
    "# Центроіди\n",
    "plt.scatter(X_ceterod, y_centroid, s=55, c=['blue', 'red'], marker='x')\n",
    "\n",
    "# Класи з датасету\n",
    "plt.scatter(data_2d[1], data_2d[2], c=data_2d[0], s=55, cmap='RdYlBu', alpha=0.2)\n",
    "\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.title(\"Visualization of clusters using K-Means\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Висновки\n",
    "\n",
    "1. Метод \"ліктя\" дає число ознак що дорівнює $2$, що підтверджується самим датасетом, де перша колонка є класом, що якої відносяться ознаки. Таких ознак там теж $2$.\n",
    "2. На графіку зображені кластери та центроїди. На кожну точку певного кластеру накладено \"ореол\" відомого нам класу с датасету. Бачимо, що алгоритм добре впорався і добре прокласифікував наші дані."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Датасет `mnist`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = pd.read_csv(\"data/mnist.csv\", header=None)\n",
    "mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Аналіз даних"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mnist = mnist.iloc[:, 1:]\n",
    "y_mnist = mnist.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = mnist[0].unique()\n",
    "classes.sort()\n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Схоже, що датасет має $10$ кластерів. Ознаки мають характеризувати якусь цифру, можливо, це рукописні образи, як показано на рисунку.\n",
    "\n",
    "![Alt text](image/digit.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Застосування PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA (Principal Component Analysis) - це метод, що використовується для зменшення розмірності даних і виділення найбільш інформативних ознак. Основна ідея PCA полягає в проєктуванні багатовимірних даних на меншу кількість вимірів (головних компонентів), при цьому максимізується збереження дисперсії даних. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca_mnist = pca.fit_transform(X_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_pca_mnist[:, 0], X_pca_mnist[:, 1],\n",
    "c=y_mnist, edgecolor='none', alpha=0.5,\n",
    "cmap='tab10')\n",
    "plt.xlabel('component 1') \n",
    "plt.ylabel('component 2') \n",
    "plt.colorbar();\n",
    "\n",
    "plt.title(\"Visualization of clusters after PCA\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дивлячись на діаграму розсіювання розфарбовану за класами, що наводяться в датасеті, не видно ніяких кластерів.\n",
    "\n",
    "Наразі, ці точки - це проекції кожної з точок даних уздовж напрямків максимальної дисперсії. По суті, ми знайшли оптимальні розтягнення і обертання в 784-вимірному просторі, що дають змогу побачити, який вигляд цифри мають у двох вимірах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Застосування методу \"ліктя\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### На даних без зниження розмірності"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jk_mnist = find_optimal_clusters(X_mnist, max_clusters=20, random_state=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут не можна надійно визначити кількість кластерів."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### На даних зі зниженням розмірності методом `PCA`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jk_pca_mnist = find_optimal_clusters(X_pca_mnist, max_clusters=20, random_state=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На цьому графіку, що побудований з використанням даних зі зниженням розмірності методом `PCA` видно, що число кластерів дорівнює $3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_mnist = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Запуск алгоритму класифікації"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels, centroids = perform_kmeans_clustering(X_pca_mnist, n_clusters=k_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "cmap = plt.get_cmap(\"Paired_r\")\n",
    "\n",
    "hull_list = [ConvexHull(X_pca_mnist[cluster_labels == i]) for i in range(k_mnist)]\n",
    "\n",
    "\n",
    "for i, hull in enumerate(hull_list):\n",
    "    cluster_points = X_pca_mnist[cluster_labels == i]\n",
    "    cluster_color = cmap(i / k_mnist)\n",
    "    plt.scatter(\n",
    "        cluster_points[:, 0],\n",
    "        cluster_points[:, 1],\n",
    "        s=10,\n",
    "        color=cluster_color,\n",
    "        label=f\"Cluster {i+1}\",\n",
    "    )\n",
    "\n",
    "    for simplex in hull.simplices:\n",
    "        plt.plot(\n",
    "            cluster_points[simplex, 0],\n",
    "            cluster_points[simplex, 1],\n",
    "            color=cluster_color,\n",
    "            linewidth=1,\n",
    "            linestyle=\"--\",\n",
    "        )\n",
    "\n",
    "    ax.fill(\n",
    "        cluster_points[hull.vertices, 0],\n",
    "        cluster_points[hull.vertices, 1],\n",
    "        facecolor=cluster_color,\n",
    "        alpha=0.2,\n",
    "    )\n",
    "\n",
    "\n",
    "ax.scatter(centroids[:, 0], centroids[:, 1], s=75, marker=\"x\", c=\"r\")\n",
    "ax.set_facecolor(\"#f5f5f5\")\n",
    "plt.xlabel(\"component 1\")\n",
    "plt.ylabel(\"component 2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Висновки\n",
    "\n",
    "Метод \"ліктя\" після зниження розмірності (використання `PCA`) надійно дає значення числа кластерів 3. Що це означає? Чому не 10? Скоріше за все йде втрата інформації після `PCA`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
