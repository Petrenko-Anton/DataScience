{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Теорія"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Означення"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кластерний аналіз (англ. Data clustering) — задача розбиття заданої вибірки об'єктів (ситуацій) на підмножини, які називаються кластерами, так, щоб кожен кластер складався зі схожих об'єктів, а об'єкти різних кластерів істотно відрізнялися. Задача кластеризації належить до статистичної обробки, а також до широкого класу завдань некерованого навчання."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кластериза́ція ме́тодом k-сере́дніх (англ. k-means clustering) - впорядкування множини об'єктів у порівняно однорідні групи.\n",
    "\n",
    "Мета методу - розділити $n$ спостережень на $k$ кластерів, так щоб кожне спостереження належало до кластера з найближчим до нього середнім значенням. Метод базується на мінімізації суми квадратів відстаней між кожним спостереженням та центром його кластера, тобто функції:\n",
    "\n",
    "\\begin{equation*}\n",
    "    J = \\sum_{i=1}^{n} \\sum_{j=1}^{k} (x_i - с_j)^2\n",
    "\\end{equation*}\n",
    "\n",
    "де $k$ — число кластерів, $n$ — число спостережень, $x_i$ - $i$-те спостереження, $c_j$ - центри мас $j$-го кластера.\n",
    "\n",
    "Фунцкція $J$ - це функція втрат, котру для кластеризації ще називають `distortion`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Алгоритм методу «Кластеризація за схемою k-середніх»:\n",
    "\n",
    "Маємо масив спостережень (об'єктів), кожен з яких має певні значення за рядом ознак. Відповідно до цих значень об'єкт розташовується у багатовимірному просторі.\n",
    "\n",
    "1. Дослідник визначає кількість кластерів, що необхідно утворити.\n",
    "2. Випадковим чином обирається $n$ спостережень, які на цьому кроці вважаються центрами кластерів.\n",
    "3. Кожне спостереження «приписується» до одного з $k$ кластерів — того, відстань до якого найкоротша.\n",
    "4. Розраховується новий центр кожного кластера як елемент, ознаки якого розраховуються як середнє арифметичне ознак об'єктів, що входять у цей кластер.\n",
    "5. Відбувається така кількість ітерацій (повторюються кроки 3-4), поки кластерні центри стануть стійкими (тобто при кожній ітерації в кожен кластер потрапляють одні й ті самі об'єкти), дисперсія всередині кластера буде мінімізована, а між кластерами — максимізована.\n",
    "\n",
    "Вибір кількості кластерів робиться на основі дослідницької гіпотези. Якщо її немає, то рекомендують спочатку створити 2 кластери, далі 3, 4, 5, порівнюючи отримані результати."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метод \"ліктя\"\n",
    "\n",
    "Метод ліктя передбачає багаторазове циклічне виконання алгоритму зі збільшенням кількості кластерів, а також подальшим відкладанням на графіку функції втрат (`distortion`).\n",
    "\n",
    "Характерный график выглядит так:\n",
    "\n",
    "![Alt text](image/kmean.png)\n",
    "\n",
    "Графік \"ліктя\" показує залежність функції втрат $V$ від кількості кластерів $k$. Якщо на графіку можна виокремити точку згину (так званий \"лікоть\"), то це може свідчити про те, що відповідна кількість кластерів є оптимальною."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Посилання\n",
    "\n",
    "1. [Алгоритм кластеризации Ллойда (K-средних, K-means)](https://www.youtube.com/watch?v=8vCuR1AndH0)\n",
    "2. [Модель кластеризации KMeans](https://www.youtube.com/watch?v=EHZJMz6zyFE&ab_channel=machinelearrrning)\n",
    "3. [Документация skikit-learn. 2.3. Кластеризация](https://scikit-learn.ru/clustering/#)\n",
    "4. [sklearn.cluster.KMeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)\n",
    "5. [Кластеризуем лучше, чем «метод локтя»](https://habr.com/ru/companies/jetinfosystems/articles/467745/)\n",
    "6. [Кластерный анализ](https://www.dmitrymakarov.ru/intro/clustering-16/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Функції"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функція для пошуку кластерів"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_clusters(features, max_clusters, random_state=0) -> list:\n",
    "    \"\"\"\n",
    "    Find the optimal number of clusters using the 'Elbow Method' for K-Means clustering.\n",
    "\n",
    "    Parameters:\n",
    "        data (array-like): The input data for clustering.\n",
    "        max_clusters (int): The maximum number of clusters to consider.\n",
    "\n",
    "    Returns:\n",
    "        distortions: list of distorsions\n",
    "\n",
    "    This function calculates the distortion (inertia) for different numbers of clusters\n",
    "    ranging from 1 to max_clusters and plots a 'Elbow Method' graph to help choose the\n",
    "    optimal number of clusters for K-Means clustering. The point where the distortion\n",
    "    starts to decrease at a slower rate often indicates the optimal number of clusters.\n",
    "    \"\"\"\n",
    "    distortions = []\n",
    "    for i in range(1, max_clusters + 1):\n",
    "        kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=100, n_init='auto', random_state=random_state).fit(features)\n",
    "        distortions.append(kmeans.inertia_)\n",
    "    \n",
    "    plt.plot(range(1, max_clusters + 1), distortions)\n",
    "    plt.plot(range(1, max_clusters + 1), distortions)\n",
    "    plt.xticks(range(1, max_clusters + 1), rotation=45)\n",
    "    plt.xlabel(r'Кількість кластерів, $k$')\n",
    "    plt.ylabel(r'Функція втрат (дисторсія)')\n",
    "    plt.title('Графік ліктя')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "    return distortions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функція для виконання алгоритму кластеризації за методом K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_kmeans_clustering(features, n_clusters=8, random_state=0):\n",
    "    \"\"\"\n",
    "    Performs clustering using the K-Means method and returns cluster labels and centroid coordinates.\n",
    "\n",
    "    Parameters:\n",
    "    - features: The array of features to cluster.\n",
    "    - n_clusters: Number of clusters (default is 8).\n",
    "    - random_state: The seed for generating random numbers (default 0).\n",
    "\n",
    "    Returns:\n",
    "    - cluster_labels: An array of cluster labels.\n",
    "    - centroids: The coordinates of the centroids of the clusters.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a K-Means object\n",
    "    kmeans = KMeans(n_clusters=n_clusters, init='k-means++', max_iter=100, n_init='auto', random_state=0)\n",
    "\n",
    "    # Clustering\n",
    "    kmeans.fit(features)\n",
    "\n",
    "    # Get cluster labels\n",
    "    cluster_labels = kmeans.labels_\n",
    "\n",
    "    # Пget the coordinates of centroids\n",
    "    centroids = kmeans.cluster_centers_\n",
    "\n",
    "    return cluster_labels, centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Двовимірний датасет `data_2d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2d = pd.read_csv(\"data/data_2d.csv\", header=None)\n",
    "data_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Цей набір даних складається з 200 рядків і 3 стовпців. Перший стовпчик - це клас, який може набувати лише двох значень: $0$ або $1$. Другий стовпець - це перша ознака, яка є дійсним числом. Третій стовпець - це друга ознака, яка також є дійсним числом. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Побудуємо розподіл даних."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "# Ознака 1 - Графік \"ящик із вусами\"\n",
    "ax1.boxplot(data_2d[1], vert=False, widths=0.7, patch_artist=True, boxprops=dict(facecolor='lightblue'), medianprops={'color': 'red'})\n",
    "ax1.set_title('Ознака 1')\n",
    "ax1.set_yticks([])\n",
    "ax1.spines['left'].set_visible(False)\n",
    "ax1.spines['top'].set_visible(False)\n",
    "ax1.spines['right'].set_visible(False)\n",
    "\n",
    "# Ознака 2 - Графік \"ящик із вусами\"\n",
    "ax2.boxplot(data_2d[2], vert=False, widths=0.7, patch_artist=True, boxprops=dict(facecolor='lightcoral'), medianprops={'color': 'blue'})\n",
    "ax2.set_title('Ознака 2')\n",
    "ax2.set_yticks([])\n",
    "ax2.spines['left'].set_visible(False)\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.spines['right'].set_visible(False)\n",
    "\n",
    "# Діаграма розсіювання\n",
    "scatter = ax3.scatter(data_2d[1], data_2d[2], c=data_2d[0], s=30, cmap='RdYlBu', alpha=0.75)\n",
    "ax3.set_title('Діаграма розсіювання')\n",
    "ax3.set_xlabel('Ознака 1')\n",
    "ax3.set_ylabel('Ознака 2')\n",
    "ax3.legend(*scatter.legend_elements(), title=\"Класи\", loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Додамо кольорові фони для кожного графіка\n",
    "ax1.set_facecolor('#f7f7f7')\n",
    "ax2.set_facecolor('#f7f7f7')\n",
    "ax3.set_facecolor('#f7f7f7')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Розрахунок кореляції\n",
    "corr = np.corrcoef(data_2d[1], data_2d[2])\n",
    "print(corr[0, 1].round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На основі графіків та коефіцієнта кореляції можна зробити висновки про дані:\n",
    "- Розподіл першої ознаки: нормальний.\n",
    "- Розподіл другої ознаки: нормальний.\n",
    "- Кореляція між ознаками: слабка."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Знаходження оптимальної кількості кластерів"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data_2d.iloc[:, 1:]\n",
    "\n",
    "Jk_data_2d = find_optimal_clusters(features, max_clusters=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Судячи з графіку число кластерів для `data_2d` дорівнює $2$. Крім того в наших даних перша колонка скоріше за все є класом ознаки. Таких ознак в даних також $2$-і."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Запуск алгоритму класифікації"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_data_2d = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels, centroids = perform_kmeans_clustering(features, n_clusters=k_data_2d)\n",
    "\n",
    "X_ceterod = centroids[:, 0]\n",
    "y_centroid = centroids[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Візуалізація результат роботи кластеризації"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кластери\n",
    "plt.scatter(x=data_2d[1], y=data_2d[2], s=10, c=cluster_labels, cmap='rainbow')\n",
    "# Центроіди\n",
    "plt.scatter(X_ceterod, y_centroid, s=55, c=['blue', 'red'], marker='x')\n",
    "\n",
    "# Класи з датасету\n",
    "plt.scatter(data_2d[1], data_2d[2], c=data_2d[0], s=55, cmap='RdYlBu', alpha=0.2)\n",
    "\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.title(\"Visualization of clusters using K-Means\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Висновки\n",
    "\n",
    "1. Метод \"ліктя\" дає число ознак що дорівнює $2$, що підтверджується самим датасетом, де перша колонка є класом, що якої відносяться ознаки. Таких ознак там теж $2$.\n",
    "2. На графіку зображені кластери та центроїди. На кожну точку певного кластеру накладено \"ореол\" відомого нам класу с датасету. Бачимо, що алгоритм добре впорався і добре прокласифікував наші дані."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Датасет `mnist`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = pd.read_csv(\"data/mnist.csv\", header=None)\n",
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mnist = mnist.iloc[:, 1:]\n",
    "y_mnist = mnist.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Аналіз даних"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = mnist[0].unique()\n",
    "classes.sort()\n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Схоже, що датасет має $10$ кластерів. Ознаки мають характеризувати якусь цифру.\n",
    "![Alt text](image/digit.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Застосування PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA (Principal Component Analysis) - це метод, що використовується для зменшення розмірності даних і виділення найбільш інформативних ознак. Основна ідея PCA полягає в проєктуванні багатовимірних даних на меншу кількість вимірів (головних компонентів), при цьому максимізується збереження дисперсії даних. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca_mnist = pca.fit_transform(X_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k', 'purple', 'orange', 'pink']\n",
    "\n",
    "for i in range(10):\n",
    "    plt.scatter(X_pca_mnist[y_mnist == i, 0], X_pca_mnist[y_mnist == i, 1], c=colors[i], label=f'Клас {i}')\n",
    "\n",
    "plt.xlabel('Головна компонента 1')\n",
    "plt.ylabel('Головна компонента 2')\n",
    "plt.title('Візуалізація кластерів після PCA')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Застосування методу \"ліктя\"\n",
    "\n",
    "Схоже, що число кластерів дорівнює $3$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "Jk_mnist = find_optimal_clusters(X_mnist, max_clusters=20, random_state=randint(0, 4294967295))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_mnist = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels, centroids = perform_kmeans_clustering(X_pca_mnist, n_clusters=k_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кластери\n",
    "plt.scatter(x=X_pca_mnist[:, 0], y=X_pca_mnist[:, 1], s=10, c=cluster_labels, cmap='rainbow')\n",
    "# Центроіди\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1], s=75, marker='x')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Висновки\n",
    "\n",
    "1. Ніякої кореляції з класами даними в датаскті `mnist` я не бачу."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
